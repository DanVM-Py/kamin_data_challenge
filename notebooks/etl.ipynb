{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Setup completo!\n",
      "📁 Raw: /app/data/raw\n",
      "📁 Processed: /app/data/processed\n"
     ]
    }
   ],
   "source": [
    "# Setup completo\n",
    "import sys\n",
    "sys.path.append('/app/src')\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Importar funciones\n",
    "from load import load_csv\n",
    "from transform import (\n",
    "    standardize_dates,\n",
    "    deduplicate_logic,\n",
    "    normalize_clients_metadata,\n",
    "    normalize_events_metadata, \n",
    "    normalize_retry_logs_metadata\n",
    ")\n",
    "\n",
    "# Definir rutas\n",
    "DATA_RAW = Path('/app/data/raw')\n",
    "DATA_PROCESSED = Path('/app/data/processed')\n",
    "\n",
    "print(\"🚀 Setup completo!\")\n",
    "print(f\"📁 Raw: {DATA_RAW}\")\n",
    "print(f\"📁 Processed: {DATA_PROCESSED}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 STEP 1: LOADING DATASETS\n",
      "========================================\n",
      "[Load CSV] Cargado clients.csv: 60 rows, 6 columns.\n",
      "[Load CSV] Cargado events.csv: 15000 rows, 11 columns.\n",
      "[Load CSV] Cargado retry_logs.csv: 1500 rows, 5 columns.\n",
      "\n",
      "✅ Datasets cargados:\n",
      "   Clients: (60, 6)\n",
      "   Events: (15000, 11)\n",
      "   Retries: (1500, 5)\n"
     ]
    }
   ],
   "source": [
    "# LOAD - Cargar datasets desde Raw\n",
    "print(\"📥 STEP 1: LOADING DATASETS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Cargar los 3 datasets\n",
    "df_clients = load_csv('clients.csv', DATA_RAW)\n",
    "df_events = load_csv('events.csv', DATA_RAW)\n",
    "df_retries = load_csv('retry_logs.csv', DATA_RAW)\n",
    "\n",
    "print(f\"\\n✅ Datasets cargados:\")\n",
    "print(f\"   Clients: {df_clients.shape}\")\n",
    "print(f\"   Events: {df_events.shape}\")\n",
    "print(f\"   Retries: {df_retries.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📅 STEP 2: STANDARDIZING DATES\n",
      "========================================\n",
      "\n",
      "📅 Estandarizando fechas en clients...\n",
      "[clients] 'sign_up_date': 0 valores no parseados\n",
      "\n",
      "📅 Estandarizando fechas en events...\n",
      "[events] 'created_at': 0 valores no parseados\n",
      "[events] 'completed_at': 3814 nulls (0 en eventos con status ≠ processing/created)\n",
      "\n",
      "📅 Estandarizando fechas en retry_logs...\n",
      "[retry_logs] 'retry_time': 0 valores no parseados\n",
      "\n",
      "✅ Estandarización de fechas completada\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n📅 STEP 2: STANDARDIZING DATES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Dates columns para cada dataset\n",
    "date_columns = {\n",
    "    'clients': ['sign_up_date'],\n",
    "    'events': ['created_at', 'completed_at'],\n",
    "    'retry_logs': ['retry_time']\n",
    "}\n",
    "\n",
    "print(\"\\n📅 Estandarizando fechas en clients...\")\n",
    "df_clients = standardize_dates(df_clients, date_columns['clients'], 'clients')\n",
    "\n",
    "print(\"\\n📅 Estandarizando fechas en events...\")\n",
    "df_events = standardize_dates(df_events, date_columns['events'], 'events')\n",
    "\n",
    "print(\"\\n📅 Estandarizando fechas en retry_logs...\")\n",
    "df_retries = standardize_dates(df_retries, date_columns['retry_logs'], 'retry_logs')\n",
    "\n",
    "print(f\"\\n✅ Estandarización de fechas completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 STEP 3: DEDUPLICATING DATA\n",
      "========================================\n",
      "\n",
      "🔧 Deduplicando clients...\n",
      "[Deduplicate] clients: 60 → 60 rows (kept earliest by sign_up_date)\n",
      "\n",
      "🔧 Deduplicando events...\n",
      "[Deduplicate] events: 15000 → 15000 rows (kept earliest by created_at)\n",
      "\n",
      "🔧 Deduplicando retry_logs...\n",
      "[Deduplicate] retry_logs: 1500 → 1500 rows (kept earliest by retry_time)\n",
      "\n",
      "✅ Deduplicación completada\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔄 STEP 3: DEDUPLICATING DATA\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\n🔧 Deduplicando clients...\")\n",
    "df_clients = deduplicate_logic(\n",
    "    df_clients, \n",
    "    subset=['client_id'], \n",
    "    sort_by='sign_up_date', \n",
    "    name='clients'\n",
    ")\n",
    "\n",
    "print(\"\\n🔧 Deduplicando events...\")\n",
    "df_events = deduplicate_logic(\n",
    "    df_events, \n",
    "    subset=['event_id'], \n",
    "    sort_by='created_at', \n",
    "    name='events'\n",
    ")\n",
    "\n",
    "print(\"\\n🔧 Deduplicando retry_logs...\")\n",
    "df_retries = deduplicate_logic(\n",
    "    df_retries, \n",
    "    subset=['retry_id'], \n",
    "    sort_by='retry_time', \n",
    "    name='retry_logs'\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Deduplicación completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 STEP 4: TRANSFORMING & NORMALIZING\n",
      "========================================\n",
      "\n",
      "🔧 Normalizando clients...\n",
      "[Metadata] clients: 17/60 sectors set to 'unknown'\n",
      "[Metadata] clients: 9/60 tiers set to 'unknown'\n",
      "\n",
      "🔧 Normalizando events...\n",
      "[Metadata] events: 15000 → 15000 after dropping missing keys\n",
      "[Metadata] events: 0/15000 invalid type set to 'unknown'\n",
      "[Metadata] events: 0/15000 invalid currency codes set to 'XXX'\n",
      "[Metadata] events: 0/15000 invalid status code set to 'unknown'\n",
      "[Metadata] events: 0/15000 invalid error code set to 'unknown'\n",
      "[Metadata] events: 0/15000 invalid origin_country codes set to 'XX'\n",
      "[Metadata] events: 0/15000 invalid destination_country codes set to 'XX'\n",
      "\n",
      "🔧 Normalizando retry_logs...\n",
      "[Metadata] retry_logs: 1500 → 1500 after dropping missing keys\n",
      "[Metadata] retry_logs: 0/1500 invalid status set to 'unknown'\n",
      "\n",
      "✅ Transformaciones completadas:\n",
      "   Clients: (60, 6) → (60, 6)\n",
      "   Events: (15000, 11) → (15000, 11)\n",
      "   Retries: (1500, 5) → (1500, 5)\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORM - Aplicar normalización\n",
    "print(\"\\n🔄 STEP 4: TRANSFORMING & NORMALIZING\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Aplicar normalización a clients\n",
    "print(\"\\n🔧 Normalizando clients...\")\n",
    "df_clients_clean = normalize_clients_metadata(df_clients)\n",
    "\n",
    "# Aplicar normalización a events\n",
    "print(\"\\n🔧 Normalizando events...\")\n",
    "df_events_clean = normalize_events_metadata(df_events)\n",
    "\n",
    "# Aplicar normalización a retry_logs\n",
    "print(\"\\n🔧 Normalizando retry_logs...\")\n",
    "df_retries_clean = normalize_retry_logs_metadata(df_retries)\n",
    "\n",
    "print(f\"\\n✅ Transformaciones completadas:\")\n",
    "print(f\"   Clients: {df_clients.shape} → {df_clients_clean.shape}\")\n",
    "print(f\"   Events: {df_events.shape} → {df_events_clean.shape}\")\n",
    "print(f\"   Retries: {df_retries.shape} → {df_retries_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 STEP 5: EXPORTING PROCESSED DATA\n",
      "========================================\n",
      "✅ Clients: /app/data/processed/clients.csv\n",
      "   Guardados: 60 filas × 6 columnas\n",
      "✅ Events: /app/data/processed/events.csv\n",
      "   Guardados: 15,000 filas × 11 columnas\n",
      "✅ Retry Logs: /app/data/processed/retry_logs.csv\n",
      "   Guardados: 1,500 filas × 5 columnas\n",
      "\n",
      "🎯 ¡Todos los datos procesados guardados en /app/data/processed!\n"
     ]
    }
   ],
   "source": [
    "# EXPORT - Guardar datos procesados\n",
    "print(\"\\n💾 STEP 5: EXPORTING PROCESSED DATA\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Función helper para exportar\n",
    "def export_to_csv(df, filename, description):\n",
    "    output_path = DATA_PROCESSED / filename\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ {description}: {output_path}\")\n",
    "    print(f\"   Guardados: {df.shape[0]:,} filas × {df.shape[1]} columnas\")\n",
    "\n",
    "# Exportar datasets limpios\n",
    "export_to_csv(df_clients_clean, 'clients.csv', 'Clients')\n",
    "export_to_csv(df_events_clean, 'events.csv', 'Events')  \n",
    "export_to_csv(df_retries_clean, 'retry_logs.csv', 'Retry Logs')\n",
    "\n",
    "print(f\"\\n🎯 ¡Todos los datos procesados guardados en {DATA_PROCESSED}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
